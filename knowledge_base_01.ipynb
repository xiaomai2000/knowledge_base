{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts.\n"
     ]
    }
   ],
   "source": [
    "print('Starts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://192.168.1.108:7890'\n",
    "os.environ['https_proxy'] = 'http://192.168.1.108:7890'\n",
    "\n",
    "! curl -I www.google.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaomai/anaconda3/envs/aikb/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载预训练模型和分词器\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = AutoModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "\n",
    "def embed_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state[:, 0, :]  # 使用[CLS] token的嵌入\n",
    "    return embeddings.squeeze().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "KB_file = \"./knowledge_base.txt\"\n",
    "\n",
    "# 读取文本数据并生成嵌入\n",
    "with open(KB_file, \"r\") as file:\n",
    "    texts = file.readlines()\n",
    "embeddings = [embed_text(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  使用FAISS存储和检索向量：\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# 创建FAISS索引\n",
    "dimension = 768  # 嵌入维度\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "embeddings_np = np.array(embeddings, dtype=np.float32)\n",
    "index.add(embeddings_np)\n",
    "\n",
    "# 保存索引\n",
    "faiss.write_index(index, \"knowledge_base.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51 47 43 55  0]]\n"
     ]
    }
   ],
   "source": [
    "#检查FAISS索引是否正确保存和加载：\n",
    "index = faiss.read_index(\"knowledge_base.index\")\n",
    "query = embed_text(\"How many data modelling examples?\")\n",
    "D, I = index.search(np.array([query], dtype=np.float32), k=5)  # 搜索前5个最相似的\n",
    "print(I)  # 输出匹配的索引\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['By modeling your data, you can document what types of data you have, how you use it, and the data management requirements surrounding its usage, protection, and governance. The benefits of data modeling include:\\n',\n",
       " \"it's not just about the results of data modeling, but how you get those results.\\n\",\n",
       " 'Now that you know what data modeling is and why it’s important, let’s look at the three different types of data modeling concepts as examples.\\n',\n",
       " 'Saving time and money on IT and process investments through appropriate planning.\\n',\n",
       " 'Creating a structure for collaboration between your IT and business teams.\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#编写查询函数，返回最匹配的文本：\n",
    "def search(query_text, top_k=5):\n",
    "    query_embedding = embed_text(query_text)\n",
    "    D, I = index.search(np.array([query_embedding], dtype=np.float32), k=top_k)\n",
    "    results = [texts[i] for i in I[0]]\n",
    "    return results\n",
    "\n",
    "# 测试查询\n",
    "results = search(\"What is the data model process? Please list the steps.\", top_k=5)\n",
    "#print(results)\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aikb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
